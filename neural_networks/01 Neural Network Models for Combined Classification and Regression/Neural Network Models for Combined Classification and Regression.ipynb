{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Regression and Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = pd.read_csv(url, header=None)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 381\n",
      "Trainable params: 381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x1a1b9fdc2e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a1b9ff05e0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a1ba010760>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 - 1s - loss: 103.3339\n",
      "Epoch 2/150\n",
      "88/88 - 0s - loss: 50.4048\n",
      "Epoch 3/150\n",
      "88/88 - 0s - loss: 13.0152\n",
      "Epoch 4/150\n",
      "88/88 - 0s - loss: 9.2655\n",
      "Epoch 5/150\n",
      "88/88 - 0s - loss: 8.8194\n",
      "Epoch 6/150\n",
      "88/88 - 0s - loss: 8.3733\n",
      "Epoch 7/150\n",
      "88/88 - 0s - loss: 7.9821\n",
      "Epoch 8/150\n",
      "88/88 - 0s - loss: 7.6973\n",
      "Epoch 9/150\n",
      "88/88 - 0s - loss: 7.4951\n",
      "Epoch 10/150\n",
      "88/88 - 0s - loss: 7.3726\n",
      "Epoch 11/150\n",
      "88/88 - 0s - loss: 7.2697\n",
      "Epoch 12/150\n",
      "88/88 - 0s - loss: 7.1713\n",
      "Epoch 13/150\n",
      "88/88 - 0s - loss: 7.1009\n",
      "Epoch 14/150\n",
      "88/88 - 0s - loss: 7.0118\n",
      "Epoch 15/150\n",
      "88/88 - 0s - loss: 6.9422\n",
      "Epoch 16/150\n",
      "88/88 - 0s - loss: 6.8563\n",
      "Epoch 17/150\n",
      "88/88 - 0s - loss: 6.7966\n",
      "Epoch 18/150\n",
      "88/88 - 0s - loss: 6.6828\n",
      "Epoch 19/150\n",
      "88/88 - 0s - loss: 6.6091\n",
      "Epoch 20/150\n",
      "88/88 - 0s - loss: 6.5072\n",
      "Epoch 21/150\n",
      "88/88 - 0s - loss: 6.4420\n",
      "Epoch 22/150\n",
      "88/88 - 0s - loss: 6.3472\n",
      "Epoch 23/150\n",
      "88/88 - 0s - loss: 6.2408\n",
      "Epoch 24/150\n",
      "88/88 - 0s - loss: 6.1514\n",
      "Epoch 25/150\n",
      "88/88 - 0s - loss: 6.0734\n",
      "Epoch 26/150\n",
      "88/88 - 0s - loss: 5.9766\n",
      "Epoch 27/150\n",
      "88/88 - 0s - loss: 5.9092\n",
      "Epoch 28/150\n",
      "88/88 - 0s - loss: 5.8113\n",
      "Epoch 29/150\n",
      "88/88 - 0s - loss: 5.7249\n",
      "Epoch 30/150\n",
      "88/88 - 0s - loss: 5.6626\n",
      "Epoch 31/150\n",
      "88/88 - 0s - loss: 5.5495\n",
      "Epoch 32/150\n",
      "88/88 - 0s - loss: 5.4596\n",
      "Epoch 33/150\n",
      "88/88 - 0s - loss: 5.3773\n",
      "Epoch 34/150\n",
      "88/88 - 0s - loss: 5.3468\n",
      "Epoch 35/150\n",
      "88/88 - 0s - loss: 5.2717\n",
      "Epoch 36/150\n",
      "88/88 - 0s - loss: 5.2449\n",
      "Epoch 37/150\n",
      "88/88 - 0s - loss: 5.1867\n",
      "Epoch 38/150\n",
      "88/88 - 0s - loss: 5.1822\n",
      "Epoch 39/150\n",
      "88/88 - 0s - loss: 5.1210\n",
      "Epoch 40/150\n",
      "88/88 - 0s - loss: 5.0911\n",
      "Epoch 41/150\n",
      "88/88 - 0s - loss: 5.0952\n",
      "Epoch 42/150\n",
      "88/88 - 0s - loss: 5.0734\n",
      "Epoch 43/150\n",
      "88/88 - 0s - loss: 5.0237\n",
      "Epoch 44/150\n",
      "88/88 - 0s - loss: 5.0236\n",
      "Epoch 45/150\n",
      "88/88 - 0s - loss: 5.0009\n",
      "Epoch 46/150\n",
      "88/88 - 0s - loss: 4.9980\n",
      "Epoch 47/150\n",
      "88/88 - 0s - loss: 4.9996\n",
      "Epoch 48/150\n",
      "88/88 - 0s - loss: 4.9972\n",
      "Epoch 49/150\n",
      "88/88 - 0s - loss: 4.9798\n",
      "Epoch 50/150\n",
      "88/88 - 0s - loss: 4.9532\n",
      "Epoch 51/150\n",
      "88/88 - 0s - loss: 4.9354\n",
      "Epoch 52/150\n",
      "88/88 - 0s - loss: 4.9231\n",
      "Epoch 53/150\n",
      "88/88 - 0s - loss: 4.9339\n",
      "Epoch 54/150\n",
      "88/88 - 0s - loss: 4.8990\n",
      "Epoch 55/150\n",
      "88/88 - 0s - loss: 4.9232\n",
      "Epoch 56/150\n",
      "88/88 - 0s - loss: 4.8985\n",
      "Epoch 57/150\n",
      "88/88 - 0s - loss: 4.8767\n",
      "Epoch 58/150\n",
      "88/88 - 0s - loss: 4.8624\n",
      "Epoch 59/150\n",
      "88/88 - 0s - loss: 4.8574\n",
      "Epoch 60/150\n",
      "88/88 - 0s - loss: 4.8432\n",
      "Epoch 61/150\n",
      "88/88 - 0s - loss: 4.8431\n",
      "Epoch 62/150\n",
      "88/88 - 0s - loss: 4.8590\n",
      "Epoch 63/150\n",
      "88/88 - 0s - loss: 4.8374\n",
      "Epoch 64/150\n",
      "88/88 - 0s - loss: 4.8266\n",
      "Epoch 65/150\n",
      "88/88 - 0s - loss: 4.8416\n",
      "Epoch 66/150\n",
      "88/88 - 0s - loss: 4.8278\n",
      "Epoch 67/150\n",
      "88/88 - 0s - loss: 4.8064\n",
      "Epoch 68/150\n",
      "88/88 - 0s - loss: 4.8096\n",
      "Epoch 69/150\n",
      "88/88 - 0s - loss: 4.7902\n",
      "Epoch 70/150\n",
      "88/88 - 0s - loss: 4.7799\n",
      "Epoch 71/150\n",
      "88/88 - 0s - loss: 4.7833\n",
      "Epoch 72/150\n",
      "88/88 - 0s - loss: 4.8129\n",
      "Epoch 73/150\n",
      "88/88 - 0s - loss: 4.8086\n",
      "Epoch 74/150\n",
      "88/88 - 0s - loss: 4.7813\n",
      "Epoch 75/150\n",
      "88/88 - 0s - loss: 4.7594\n",
      "Epoch 76/150\n",
      "88/88 - 0s - loss: 4.7863\n",
      "Epoch 77/150\n",
      "88/88 - 0s - loss: 4.7806\n",
      "Epoch 78/150\n",
      "88/88 - 0s - loss: 4.7495\n",
      "Epoch 79/150\n",
      "88/88 - 0s - loss: 4.8219\n",
      "Epoch 80/150\n",
      "88/88 - 0s - loss: 4.7595\n",
      "Epoch 81/150\n",
      "88/88 - 0s - loss: 4.7387\n",
      "Epoch 82/150\n",
      "88/88 - 0s - loss: 4.7477\n",
      "Epoch 83/150\n",
      "88/88 - 0s - loss: 4.7264\n",
      "Epoch 84/150\n",
      "88/88 - 0s - loss: 4.7198\n",
      "Epoch 85/150\n",
      "88/88 - 0s - loss: 4.7414\n",
      "Epoch 86/150\n",
      "88/88 - 0s - loss: 4.7161\n",
      "Epoch 87/150\n",
      "88/88 - 0s - loss: 4.7295\n",
      "Epoch 88/150\n",
      "88/88 - 0s - loss: 4.7194\n",
      "Epoch 89/150\n",
      "88/88 - 0s - loss: 4.7143\n",
      "Epoch 90/150\n",
      "88/88 - 0s - loss: 4.7057\n",
      "Epoch 91/150\n",
      "88/88 - 0s - loss: 4.7311\n",
      "Epoch 92/150\n",
      "88/88 - 0s - loss: 4.7014\n",
      "Epoch 93/150\n",
      "88/88 - 0s - loss: 4.6929\n",
      "Epoch 94/150\n",
      "88/88 - 0s - loss: 4.6959\n",
      "Epoch 95/150\n",
      "88/88 - 0s - loss: 4.6927\n",
      "Epoch 96/150\n",
      "88/88 - 0s - loss: 4.7196\n",
      "Epoch 97/150\n",
      "88/88 - 0s - loss: 4.6896\n",
      "Epoch 98/150\n",
      "88/88 - 0s - loss: 4.6823\n",
      "Epoch 99/150\n",
      "88/88 - 0s - loss: 4.6717\n",
      "Epoch 100/150\n",
      "88/88 - 0s - loss: 4.6708\n",
      "Epoch 101/150\n",
      "88/88 - 0s - loss: 4.6737\n",
      "Epoch 102/150\n",
      "88/88 - 0s - loss: 4.6530\n",
      "Epoch 103/150\n",
      "88/88 - 0s - loss: 4.7016\n",
      "Epoch 104/150\n",
      "88/88 - 0s - loss: 4.7295\n",
      "Epoch 105/150\n",
      "88/88 - 0s - loss: 4.6891\n",
      "Epoch 106/150\n",
      "88/88 - 0s - loss: 4.6459\n",
      "Epoch 107/150\n",
      "88/88 - 0s - loss: 4.6905\n",
      "Epoch 108/150\n",
      "88/88 - 0s - loss: 4.6579\n",
      "Epoch 109/150\n",
      "88/88 - 0s - loss: 4.6887\n",
      "Epoch 110/150\n",
      "88/88 - 0s - loss: 4.6764\n",
      "Epoch 111/150\n",
      "88/88 - 0s - loss: 4.6544\n",
      "Epoch 112/150\n",
      "88/88 - 0s - loss: 4.6411\n",
      "Epoch 113/150\n",
      "88/88 - 0s - loss: 4.6204\n",
      "Epoch 114/150\n",
      "88/88 - 0s - loss: 4.6176\n",
      "Epoch 115/150\n",
      "88/88 - 0s - loss: 4.6177\n",
      "Epoch 116/150\n",
      "88/88 - 0s - loss: 4.6348\n",
      "Epoch 117/150\n",
      "88/88 - 0s - loss: 4.6144\n",
      "Epoch 118/150\n",
      "88/88 - 0s - loss: 4.6146\n",
      "Epoch 119/150\n",
      "88/88 - 0s - loss: 4.6108\n",
      "Epoch 120/150\n",
      "88/88 - 0s - loss: 4.6148\n",
      "Epoch 121/150\n",
      "88/88 - 0s - loss: 4.6333\n",
      "Epoch 122/150\n",
      "88/88 - 0s - loss: 4.6097\n",
      "Epoch 123/150\n",
      "88/88 - 0s - loss: 4.6120\n",
      "Epoch 124/150\n",
      "88/88 - 0s - loss: 4.5850\n",
      "Epoch 125/150\n",
      "88/88 - 0s - loss: 4.5952\n",
      "Epoch 126/150\n",
      "88/88 - 0s - loss: 4.6060\n",
      "Epoch 127/150\n",
      "88/88 - 0s - loss: 4.6250\n",
      "Epoch 128/150\n",
      "88/88 - 0s - loss: 4.6201\n",
      "Epoch 129/150\n",
      "88/88 - 0s - loss: 4.5852\n",
      "Epoch 130/150\n",
      "88/88 - 0s - loss: 4.6059\n",
      "Epoch 131/150\n",
      "88/88 - 0s - loss: 4.5818\n",
      "Epoch 132/150\n",
      "88/88 - 0s - loss: 4.5926\n",
      "Epoch 133/150\n",
      "88/88 - 0s - loss: 4.6046\n",
      "Epoch 134/150\n",
      "88/88 - 0s - loss: 4.5789\n",
      "Epoch 135/150\n",
      "88/88 - 0s - loss: 4.6160\n",
      "Epoch 136/150\n",
      "88/88 - 0s - loss: 4.5752\n",
      "Epoch 137/150\n",
      "88/88 - 0s - loss: 4.5815\n",
      "Epoch 138/150\n",
      "88/88 - 0s - loss: 4.5731\n",
      "Epoch 139/150\n",
      "88/88 - 0s - loss: 4.6194\n",
      "Epoch 140/150\n",
      "88/88 - 0s - loss: 4.6142\n",
      "Epoch 141/150\n",
      "88/88 - 0s - loss: 4.5845\n",
      "Epoch 142/150\n",
      "88/88 - 0s - loss: 4.5701\n",
      "Epoch 143/150\n",
      "88/88 - 0s - loss: 4.5894\n",
      "Epoch 144/150\n",
      "88/88 - 0s - loss: 4.5773\n",
      "Epoch 145/150\n",
      "88/88 - 0s - loss: 4.5738\n",
      "Epoch 146/150\n",
      "88/88 - 0s - loss: 4.6175\n",
      "Epoch 147/150\n",
      "88/88 - 0s - loss: 4.5908\n",
      "Epoch 148/150\n",
      "88/88 - 0s - loss: 4.5755\n",
      "Epoch 149/150\n",
      "88/88 - 0s - loss: 4.5682\n",
      "Epoch 150/150\n",
      "88/88 - 0s - loss: 4.5955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1ba0c51c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.493\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "yhat = model.predict(x_test)\n",
    "error = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = pd.read_csv(url, header=None)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "n_class = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 - 1s - loss: 3.0800\n",
      "Epoch 2/150\n",
      "88/88 - 0s - loss: 2.6777\n",
      "Epoch 3/150\n",
      "88/88 - 0s - loss: 2.4722\n",
      "Epoch 4/150\n",
      "88/88 - 0s - loss: 2.3839\n",
      "Epoch 5/150\n",
      "88/88 - 0s - loss: 2.3210\n",
      "Epoch 6/150\n",
      "88/88 - 0s - loss: 2.2779\n",
      "Epoch 7/150\n",
      "88/88 - 0s - loss: 2.2524\n",
      "Epoch 8/150\n",
      "88/88 - 0s - loss: 2.2323\n",
      "Epoch 9/150\n",
      "88/88 - 0s - loss: 2.2183\n",
      "Epoch 10/150\n",
      "88/88 - 0s - loss: 2.2063\n",
      "Epoch 11/150\n",
      "88/88 - 0s - loss: 2.1955\n",
      "Epoch 12/150\n",
      "88/88 - 0s - loss: 2.1880\n",
      "Epoch 13/150\n",
      "88/88 - 0s - loss: 2.1799\n",
      "Epoch 14/150\n",
      "88/88 - 0s - loss: 2.1731\n",
      "Epoch 15/150\n",
      "88/88 - 0s - loss: 2.1665\n",
      "Epoch 16/150\n",
      "88/88 - 0s - loss: 2.1601\n",
      "Epoch 17/150\n",
      "88/88 - 0s - loss: 2.1554\n",
      "Epoch 18/150\n",
      "88/88 - 0s - loss: 2.1501\n",
      "Epoch 19/150\n",
      "88/88 - 0s - loss: 2.1444\n",
      "Epoch 20/150\n",
      "88/88 - 0s - loss: 2.1389\n",
      "Epoch 21/150\n",
      "88/88 - 0s - loss: 2.1351\n",
      "Epoch 22/150\n",
      "88/88 - 0s - loss: 2.1322\n",
      "Epoch 23/150\n",
      "88/88 - 0s - loss: 2.1262\n",
      "Epoch 24/150\n",
      "88/88 - 0s - loss: 2.1223\n",
      "Epoch 25/150\n",
      "88/88 - 0s - loss: 2.1162\n",
      "Epoch 26/150\n",
      "88/88 - 0s - loss: 2.1091\n",
      "Epoch 27/150\n",
      "88/88 - 0s - loss: 2.1029\n",
      "Epoch 28/150\n",
      "88/88 - 0s - loss: 2.0960\n",
      "Epoch 29/150\n",
      "88/88 - 0s - loss: 2.0910\n",
      "Epoch 30/150\n",
      "88/88 - 0s - loss: 2.0856\n",
      "Epoch 31/150\n",
      "88/88 - 0s - loss: 2.0792\n",
      "Epoch 32/150\n",
      "88/88 - 0s - loss: 2.0730\n",
      "Epoch 33/150\n",
      "88/88 - 0s - loss: 2.0677\n",
      "Epoch 34/150\n",
      "88/88 - 0s - loss: 2.0604\n",
      "Epoch 35/150\n",
      "88/88 - 0s - loss: 2.0546\n",
      "Epoch 36/150\n",
      "88/88 - 0s - loss: 2.0513\n",
      "Epoch 37/150\n",
      "88/88 - 0s - loss: 2.0442\n",
      "Epoch 38/150\n",
      "88/88 - 0s - loss: 2.0348\n",
      "Epoch 39/150\n",
      "88/88 - 0s - loss: 2.0256\n",
      "Epoch 40/150\n",
      "88/88 - 0s - loss: 2.0193\n",
      "Epoch 41/150\n",
      "88/88 - 0s - loss: 2.0138\n",
      "Epoch 42/150\n",
      "88/88 - 0s - loss: 2.0096\n",
      "Epoch 43/150\n",
      "88/88 - 0s - loss: 2.0030\n",
      "Epoch 44/150\n",
      "88/88 - 0s - loss: 1.9984\n",
      "Epoch 45/150\n",
      "88/88 - 0s - loss: 1.9966\n",
      "Epoch 46/150\n",
      "88/88 - 0s - loss: 1.9907\n",
      "Epoch 47/150\n",
      "88/88 - 0s - loss: 1.9884\n",
      "Epoch 48/150\n",
      "88/88 - 0s - loss: 1.9834\n",
      "Epoch 49/150\n",
      "88/88 - 0s - loss: 1.9804\n",
      "Epoch 50/150\n",
      "88/88 - 0s - loss: 1.9781\n",
      "Epoch 51/150\n",
      "88/88 - 0s - loss: 1.9759\n",
      "Epoch 52/150\n",
      "88/88 - 0s - loss: 1.9731\n",
      "Epoch 53/150\n",
      "88/88 - 0s - loss: 1.9700\n",
      "Epoch 54/150\n",
      "88/88 - 0s - loss: 1.9680\n",
      "Epoch 55/150\n",
      "88/88 - 0s - loss: 1.9674\n",
      "Epoch 56/150\n",
      "88/88 - 0s - loss: 1.9644\n",
      "Epoch 57/150\n",
      "88/88 - 0s - loss: 1.9622\n",
      "Epoch 58/150\n",
      "88/88 - 0s - loss: 1.9620\n",
      "Epoch 59/150\n",
      "88/88 - 0s - loss: 1.9602\n",
      "Epoch 60/150\n",
      "88/88 - 0s - loss: 1.9579\n",
      "Epoch 61/150\n",
      "88/88 - 0s - loss: 1.9572\n",
      "Epoch 62/150\n",
      "88/88 - 0s - loss: 1.9554\n",
      "Epoch 63/150\n",
      "88/88 - 0s - loss: 1.9549\n",
      "Epoch 64/150\n",
      "88/88 - 0s - loss: 1.9535\n",
      "Epoch 65/150\n",
      "88/88 - 0s - loss: 1.9514\n",
      "Epoch 66/150\n",
      "88/88 - 0s - loss: 1.9518\n",
      "Epoch 67/150\n",
      "88/88 - 0s - loss: 1.9506\n",
      "Epoch 68/150\n",
      "88/88 - 0s - loss: 1.9492\n",
      "Epoch 69/150\n",
      "88/88 - 0s - loss: 1.9462\n",
      "Epoch 70/150\n",
      "88/88 - 0s - loss: 1.9488\n",
      "Epoch 71/150\n",
      "88/88 - 0s - loss: 1.9469\n",
      "Epoch 72/150\n",
      "88/88 - 0s - loss: 1.9460\n",
      "Epoch 73/150\n",
      "88/88 - 0s - loss: 1.9442\n",
      "Epoch 74/150\n",
      "88/88 - 0s - loss: 1.9438\n",
      "Epoch 75/150\n",
      "88/88 - 0s - loss: 1.9444\n",
      "Epoch 76/150\n",
      "88/88 - 0s - loss: 1.9411\n",
      "Epoch 77/150\n",
      "88/88 - 0s - loss: 1.9412\n",
      "Epoch 78/150\n",
      "88/88 - 0s - loss: 1.9406\n",
      "Epoch 79/150\n",
      "88/88 - 0s - loss: 1.9387\n",
      "Epoch 80/150\n",
      "88/88 - 0s - loss: 1.9404\n",
      "Epoch 81/150\n",
      "88/88 - 0s - loss: 1.9399\n",
      "Epoch 82/150\n",
      "88/88 - 0s - loss: 1.9382\n",
      "Epoch 83/150\n",
      "88/88 - 0s - loss: 1.9383\n",
      "Epoch 84/150\n",
      "88/88 - 0s - loss: 1.9392\n",
      "Epoch 85/150\n",
      "88/88 - 0s - loss: 1.9365\n",
      "Epoch 86/150\n",
      "88/88 - 0s - loss: 1.9357\n",
      "Epoch 87/150\n",
      "88/88 - 0s - loss: 1.9355\n",
      "Epoch 88/150\n",
      "88/88 - 0s - loss: 1.9355\n",
      "Epoch 89/150\n",
      "88/88 - 0s - loss: 1.9347\n",
      "Epoch 90/150\n",
      "88/88 - 0s - loss: 1.9337\n",
      "Epoch 91/150\n",
      "88/88 - 0s - loss: 1.9345\n",
      "Epoch 92/150\n",
      "88/88 - 0s - loss: 1.9324\n",
      "Epoch 93/150\n",
      "88/88 - 0s - loss: 1.9318\n",
      "Epoch 94/150\n",
      "88/88 - 0s - loss: 1.9341\n",
      "Epoch 95/150\n",
      "88/88 - 0s - loss: 1.9321\n",
      "Epoch 96/150\n",
      "88/88 - 0s - loss: 1.9304\n",
      "Epoch 97/150\n",
      "88/88 - 0s - loss: 1.9317\n",
      "Epoch 98/150\n",
      "88/88 - 0s - loss: 1.9325\n",
      "Epoch 99/150\n",
      "88/88 - 0s - loss: 1.9323\n",
      "Epoch 100/150\n",
      "88/88 - 0s - loss: 1.9306\n",
      "Epoch 101/150\n",
      "88/88 - 0s - loss: 1.9316\n",
      "Epoch 102/150\n",
      "88/88 - 0s - loss: 1.9289\n",
      "Epoch 103/150\n",
      "88/88 - 0s - loss: 1.9291\n",
      "Epoch 104/150\n",
      "88/88 - 0s - loss: 1.9296\n",
      "Epoch 105/150\n",
      "88/88 - 0s - loss: 1.9295\n",
      "Epoch 106/150\n",
      "88/88 - 0s - loss: 1.9299\n",
      "Epoch 107/150\n",
      "88/88 - 0s - loss: 1.9286\n",
      "Epoch 108/150\n",
      "88/88 - 0s - loss: 1.9286\n",
      "Epoch 109/150\n",
      "88/88 - 0s - loss: 1.9314\n",
      "Epoch 110/150\n",
      "88/88 - 0s - loss: 1.9253\n",
      "Epoch 111/150\n",
      "88/88 - 0s - loss: 1.9286\n",
      "Epoch 112/150\n",
      "88/88 - 0s - loss: 1.9268\n",
      "Epoch 113/150\n",
      "88/88 - 0s - loss: 1.9276\n",
      "Epoch 114/150\n",
      "88/88 - 0s - loss: 1.9265\n",
      "Epoch 115/150\n",
      "88/88 - 0s - loss: 1.9267\n",
      "Epoch 116/150\n",
      "88/88 - 0s - loss: 1.9259\n",
      "Epoch 117/150\n",
      "88/88 - 0s - loss: 1.9239\n",
      "Epoch 118/150\n",
      "88/88 - 0s - loss: 1.9273\n",
      "Epoch 119/150\n",
      "88/88 - 0s - loss: 1.9243\n",
      "Epoch 120/150\n",
      "88/88 - 0s - loss: 1.9243\n",
      "Epoch 121/150\n",
      "88/88 - 0s - loss: 1.9242\n",
      "Epoch 122/150\n",
      "88/88 - 0s - loss: 1.9225\n",
      "Epoch 123/150\n",
      "88/88 - 0s - loss: 1.9260\n",
      "Epoch 124/150\n",
      "88/88 - 0s - loss: 1.9250\n",
      "Epoch 125/150\n",
      "88/88 - 0s - loss: 1.9245\n",
      "Epoch 126/150\n",
      "88/88 - 0s - loss: 1.9243\n",
      "Epoch 127/150\n",
      "88/88 - 0s - loss: 1.9239\n",
      "Epoch 128/150\n",
      "88/88 - 0s - loss: 1.9218\n",
      "Epoch 129/150\n",
      "88/88 - 0s - loss: 1.9220\n",
      "Epoch 130/150\n",
      "88/88 - 0s - loss: 1.9227\n",
      "Epoch 131/150\n",
      "88/88 - 0s - loss: 1.9223\n",
      "Epoch 132/150\n",
      "88/88 - 0s - loss: 1.9225\n",
      "Epoch 133/150\n",
      "88/88 - 0s - loss: 1.9211\n",
      "Epoch 134/150\n",
      "88/88 - 0s - loss: 1.9255\n",
      "Epoch 135/150\n",
      "88/88 - 0s - loss: 1.9228\n",
      "Epoch 136/150\n",
      "88/88 - 0s - loss: 1.9258\n",
      "Epoch 137/150\n",
      "88/88 - 0s - loss: 1.9217\n",
      "Epoch 138/150\n",
      "88/88 - 0s - loss: 1.9212\n",
      "Epoch 139/150\n",
      "88/88 - 0s - loss: 1.9203\n",
      "Epoch 140/150\n",
      "88/88 - 0s - loss: 1.9197\n",
      "Epoch 141/150\n",
      "88/88 - 0s - loss: 1.9201\n",
      "Epoch 142/150\n",
      "88/88 - 0s - loss: 1.9201\n",
      "Epoch 143/150\n",
      "88/88 - 0s - loss: 1.9215\n",
      "Epoch 144/150\n",
      "88/88 - 0s - loss: 1.9214\n",
      "Epoch 145/150\n",
      "88/88 - 0s - loss: 1.9217\n",
      "Epoch 146/150\n",
      "88/88 - 0s - loss: 1.9182\n",
      "Epoch 147/150\n",
      "88/88 - 0s - loss: 1.9210\n",
      "Epoch 148/150\n",
      "88/88 - 0s - loss: 1.9182\n",
      "Epoch 149/150\n",
      "88/88 - 0s - loss: 1.9204\n",
      "Epoch 150/150\n",
      "88/88 - 0s - loss: 1.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1ba5750a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.281\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "yhat = model.predict(X_test)\n",
    "yhat = np.argmax(yhat, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Regression and Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = pd.read_csv(url, header=None)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode strings to integer\n",
    "y_class = LabelEncoder().fit_transform(y)\n",
    "n_class = len(np.unique(y_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test, y_train_class, y_test_class = train_test_split(X, y, y_class, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "visible = keras.layers.Input(shape=(n_features))\n",
    "hidden1 = keras.layers.Dense(20, activation='relu', kernel_initializer='he_normal')(visible)\n",
    "hidden2 = keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression output\n",
    "out_reg = keras.layers.Dense(1, activation='linear')(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification output\n",
    "out_clas = keras.layers.Dense(n_class, activation='softmax')(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = tf.keras.models.Model(inputs=visible, outputs=[out_reg, out_clas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss=['mse','sparse_categorical_crossentropy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "88/88 - 1s - loss: 74.0079 - dense_8_loss: 70.7996 - dense_9_loss: 3.2083\n",
      "Epoch 2/150\n",
      "88/88 - 0s - loss: 21.9729 - dense_8_loss: 19.1253 - dense_9_loss: 2.8476\n",
      "Epoch 3/150\n",
      "88/88 - 0s - loss: 11.6128 - dense_8_loss: 9.0195 - dense_9_loss: 2.5932\n",
      "Epoch 4/150\n",
      "88/88 - 0s - loss: 11.0462 - dense_8_loss: 8.5147 - dense_9_loss: 2.5315\n",
      "Epoch 5/150\n",
      "88/88 - 0s - loss: 10.5773 - dense_8_loss: 8.0742 - dense_9_loss: 2.5030\n",
      "Epoch 6/150\n",
      "88/88 - 0s - loss: 10.1366 - dense_8_loss: 7.6540 - dense_9_loss: 2.4826\n",
      "Epoch 7/150\n",
      "88/88 - 0s - loss: 9.7529 - dense_8_loss: 7.2970 - dense_9_loss: 2.4560\n",
      "Epoch 8/150\n",
      "88/88 - 0s - loss: 9.4403 - dense_8_loss: 7.0225 - dense_9_loss: 2.4178\n",
      "Epoch 9/150\n",
      "88/88 - 0s - loss: 9.2258 - dense_8_loss: 6.8407 - dense_9_loss: 2.3852\n",
      "Epoch 10/150\n",
      "88/88 - 0s - loss: 9.0551 - dense_8_loss: 6.6960 - dense_9_loss: 2.3590\n",
      "Epoch 11/150\n",
      "88/88 - 0s - loss: 8.9453 - dense_8_loss: 6.6083 - dense_9_loss: 2.3370\n",
      "Epoch 12/150\n",
      "88/88 - 0s - loss: 8.8569 - dense_8_loss: 6.5358 - dense_9_loss: 2.3212\n",
      "Epoch 13/150\n",
      "88/88 - 0s - loss: 8.7575 - dense_8_loss: 6.4489 - dense_9_loss: 2.3086\n",
      "Epoch 14/150\n",
      "88/88 - 0s - loss: 8.6738 - dense_8_loss: 6.3735 - dense_9_loss: 2.3004\n",
      "Epoch 15/150\n",
      "88/88 - 0s - loss: 8.5791 - dense_8_loss: 6.2906 - dense_9_loss: 2.2885\n",
      "Epoch 16/150\n",
      "88/88 - 0s - loss: 8.4906 - dense_8_loss: 6.2121 - dense_9_loss: 2.2785\n",
      "Epoch 17/150\n",
      "88/88 - 0s - loss: 8.3935 - dense_8_loss: 6.1191 - dense_9_loss: 2.2744\n",
      "Epoch 18/150\n",
      "88/88 - 0s - loss: 8.3399 - dense_8_loss: 6.0748 - dense_9_loss: 2.2652\n",
      "Epoch 19/150\n",
      "88/88 - 0s - loss: 8.2232 - dense_8_loss: 5.9600 - dense_9_loss: 2.2632\n",
      "Epoch 20/150\n",
      "88/88 - 0s - loss: 8.1481 - dense_8_loss: 5.8866 - dense_9_loss: 2.2615\n",
      "Epoch 21/150\n",
      "88/88 - 0s - loss: 8.0622 - dense_8_loss: 5.8027 - dense_9_loss: 2.2595\n",
      "Epoch 22/150\n",
      "88/88 - 0s - loss: 7.9819 - dense_8_loss: 5.7226 - dense_9_loss: 2.2594\n",
      "Epoch 23/150\n",
      "88/88 - 0s - loss: 7.9269 - dense_8_loss: 5.6666 - dense_9_loss: 2.2603\n",
      "Epoch 24/150\n",
      "88/88 - 0s - loss: 7.8165 - dense_8_loss: 5.5583 - dense_9_loss: 2.2582\n",
      "Epoch 25/150\n",
      "88/88 - 0s - loss: 7.7489 - dense_8_loss: 5.4897 - dense_9_loss: 2.2592\n",
      "Epoch 26/150\n",
      "88/88 - 0s - loss: 7.6680 - dense_8_loss: 5.4090 - dense_9_loss: 2.2591\n",
      "Epoch 27/150\n",
      "88/88 - 0s - loss: 7.5863 - dense_8_loss: 5.3286 - dense_9_loss: 2.2577\n",
      "Epoch 28/150\n",
      "88/88 - 0s - loss: 7.5531 - dense_8_loss: 5.2945 - dense_9_loss: 2.2586\n",
      "Epoch 29/150\n",
      "88/88 - 0s - loss: 7.5007 - dense_8_loss: 5.2454 - dense_9_loss: 2.2554\n",
      "Epoch 30/150\n",
      "88/88 - 0s - loss: 7.4567 - dense_8_loss: 5.2042 - dense_9_loss: 2.2525\n",
      "Epoch 31/150\n",
      "88/88 - 0s - loss: 7.3918 - dense_8_loss: 5.1391 - dense_9_loss: 2.2528\n",
      "Epoch 32/150\n",
      "88/88 - 0s - loss: 7.3795 - dense_8_loss: 5.1332 - dense_9_loss: 2.2463\n",
      "Epoch 33/150\n",
      "88/88 - 0s - loss: 7.3361 - dense_8_loss: 5.0917 - dense_9_loss: 2.2444\n",
      "Epoch 34/150\n",
      "88/88 - 0s - loss: 7.3037 - dense_8_loss: 5.0623 - dense_9_loss: 2.2414\n",
      "Epoch 35/150\n",
      "88/88 - 0s - loss: 7.2933 - dense_8_loss: 5.0552 - dense_9_loss: 2.2381\n",
      "Epoch 36/150\n",
      "88/88 - 0s - loss: 7.2646 - dense_8_loss: 5.0299 - dense_9_loss: 2.2348\n",
      "Epoch 37/150\n",
      "88/88 - 0s - loss: 7.2577 - dense_8_loss: 5.0276 - dense_9_loss: 2.2301\n",
      "Epoch 38/150\n",
      "88/88 - 0s - loss: 7.2350 - dense_8_loss: 5.0089 - dense_9_loss: 2.2261\n",
      "Epoch 39/150\n",
      "88/88 - 0s - loss: 7.2478 - dense_8_loss: 5.0261 - dense_9_loss: 2.2217\n",
      "Epoch 40/150\n",
      "88/88 - 0s - loss: 7.2125 - dense_8_loss: 4.9959 - dense_9_loss: 2.2166\n",
      "Epoch 41/150\n",
      "88/88 - 0s - loss: 7.1748 - dense_8_loss: 4.9620 - dense_9_loss: 2.2129\n",
      "Epoch 42/150\n",
      "88/88 - 0s - loss: 7.2059 - dense_8_loss: 4.9983 - dense_9_loss: 2.2076\n",
      "Epoch 43/150\n",
      "88/88 - 0s - loss: 7.1769 - dense_8_loss: 4.9742 - dense_9_loss: 2.2027\n",
      "Epoch 44/150\n",
      "88/88 - 0s - loss: 7.1734 - dense_8_loss: 4.9757 - dense_9_loss: 2.1978\n",
      "Epoch 45/150\n",
      "88/88 - 0s - loss: 7.1505 - dense_8_loss: 4.9559 - dense_9_loss: 2.1946\n",
      "Epoch 46/150\n",
      "88/88 - 0s - loss: 7.1355 - dense_8_loss: 4.9456 - dense_9_loss: 2.1899\n",
      "Epoch 47/150\n",
      "88/88 - 0s - loss: 7.1351 - dense_8_loss: 4.9508 - dense_9_loss: 2.1843\n",
      "Epoch 48/150\n",
      "88/88 - 0s - loss: 7.1204 - dense_8_loss: 4.9385 - dense_9_loss: 2.1819\n",
      "Epoch 49/150\n",
      "88/88 - 0s - loss: 7.1909 - dense_8_loss: 5.0138 - dense_9_loss: 2.1771\n",
      "Epoch 50/150\n",
      "88/88 - 0s - loss: 7.1099 - dense_8_loss: 4.9391 - dense_9_loss: 2.1708\n",
      "Epoch 51/150\n",
      "88/88 - 0s - loss: 7.0998 - dense_8_loss: 4.9351 - dense_9_loss: 2.1648\n",
      "Epoch 52/150\n",
      "88/88 - 0s - loss: 7.1154 - dense_8_loss: 4.9530 - dense_9_loss: 2.1624\n",
      "Epoch 53/150\n",
      "88/88 - 0s - loss: 7.0896 - dense_8_loss: 4.9295 - dense_9_loss: 2.1600\n",
      "Epoch 54/150\n",
      "88/88 - 0s - loss: 7.0802 - dense_8_loss: 4.9263 - dense_9_loss: 2.1539\n",
      "Epoch 55/150\n",
      "88/88 - 0s - loss: 7.0735 - dense_8_loss: 4.9241 - dense_9_loss: 2.1494\n",
      "Epoch 56/150\n",
      "88/88 - 0s - loss: 7.0923 - dense_8_loss: 4.9466 - dense_9_loss: 2.1457\n",
      "Epoch 57/150\n",
      "88/88 - 0s - loss: 7.1144 - dense_8_loss: 4.9736 - dense_9_loss: 2.1408\n",
      "Epoch 58/150\n",
      "88/88 - 0s - loss: 7.0458 - dense_8_loss: 4.9095 - dense_9_loss: 2.1363\n",
      "Epoch 59/150\n",
      "88/88 - 0s - loss: 7.0450 - dense_8_loss: 4.9127 - dense_9_loss: 2.1322\n",
      "Epoch 60/150\n",
      "88/88 - 0s - loss: 7.0344 - dense_8_loss: 4.9064 - dense_9_loss: 2.1280\n",
      "Epoch 61/150\n",
      "88/88 - 0s - loss: 7.0337 - dense_8_loss: 4.9081 - dense_9_loss: 2.1256\n",
      "Epoch 62/150\n",
      "88/88 - 0s - loss: 7.0347 - dense_8_loss: 4.9124 - dense_9_loss: 2.1223\n",
      "Epoch 63/150\n",
      "88/88 - 0s - loss: 7.0225 - dense_8_loss: 4.9043 - dense_9_loss: 2.1183\n",
      "Epoch 64/150\n",
      "88/88 - 0s - loss: 7.0675 - dense_8_loss: 4.9526 - dense_9_loss: 2.1150\n",
      "Epoch 65/150\n",
      "88/88 - 0s - loss: 7.0382 - dense_8_loss: 4.9268 - dense_9_loss: 2.1113\n",
      "Epoch 66/150\n",
      "88/88 - 0s - loss: 7.0204 - dense_8_loss: 4.9145 - dense_9_loss: 2.1059\n",
      "Epoch 67/150\n",
      "88/88 - 0s - loss: 7.0239 - dense_8_loss: 4.9192 - dense_9_loss: 2.1047\n",
      "Epoch 68/150\n",
      "88/88 - 0s - loss: 6.9966 - dense_8_loss: 4.8953 - dense_9_loss: 2.1014\n",
      "Epoch 69/150\n",
      "88/88 - 0s - loss: 6.9931 - dense_8_loss: 4.8955 - dense_9_loss: 2.0976\n",
      "Epoch 70/150\n",
      "88/88 - 0s - loss: 7.0093 - dense_8_loss: 4.9147 - dense_9_loss: 2.0947\n",
      "Epoch 71/150\n",
      "88/88 - 0s - loss: 6.9813 - dense_8_loss: 4.8906 - dense_9_loss: 2.0907\n",
      "Epoch 72/150\n",
      "88/88 - 0s - loss: 7.0285 - dense_8_loss: 4.9398 - dense_9_loss: 2.0888\n",
      "Epoch 73/150\n",
      "88/88 - 0s - loss: 6.9953 - dense_8_loss: 4.9097 - dense_9_loss: 2.0856\n",
      "Epoch 74/150\n",
      "88/88 - 0s - loss: 6.9665 - dense_8_loss: 4.8836 - dense_9_loss: 2.0829\n",
      "Epoch 75/150\n",
      "88/88 - 0s - loss: 6.9777 - dense_8_loss: 4.8971 - dense_9_loss: 2.0806\n",
      "Epoch 76/150\n",
      "88/88 - 0s - loss: 6.9964 - dense_8_loss: 4.9194 - dense_9_loss: 2.0770\n",
      "Epoch 77/150\n",
      "88/88 - 0s - loss: 6.9697 - dense_8_loss: 4.8954 - dense_9_loss: 2.0743\n",
      "Epoch 78/150\n",
      "88/88 - 0s - loss: 7.0125 - dense_8_loss: 4.9388 - dense_9_loss: 2.0737\n",
      "Epoch 79/150\n",
      "88/88 - 0s - loss: 6.9553 - dense_8_loss: 4.8866 - dense_9_loss: 2.0687\n",
      "Epoch 80/150\n",
      "88/88 - 0s - loss: 6.9590 - dense_8_loss: 4.8917 - dense_9_loss: 2.0673\n",
      "Epoch 81/150\n",
      "88/88 - 0s - loss: 6.9476 - dense_8_loss: 4.8832 - dense_9_loss: 2.0644\n",
      "Epoch 82/150\n",
      "88/88 - 0s - loss: 6.9243 - dense_8_loss: 4.8630 - dense_9_loss: 2.0614\n",
      "Epoch 83/150\n",
      "88/88 - 0s - loss: 6.9215 - dense_8_loss: 4.8624 - dense_9_loss: 2.0591\n",
      "Epoch 84/150\n",
      "88/88 - 0s - loss: 6.9521 - dense_8_loss: 4.8944 - dense_9_loss: 2.0577\n",
      "Epoch 85/150\n",
      "88/88 - 0s - loss: 6.9222 - dense_8_loss: 4.8675 - dense_9_loss: 2.0547\n",
      "Epoch 86/150\n",
      "88/88 - 0s - loss: 6.9836 - dense_8_loss: 4.9306 - dense_9_loss: 2.0530\n",
      "Epoch 87/150\n",
      "88/88 - 0s - loss: 6.9364 - dense_8_loss: 4.8871 - dense_9_loss: 2.0493\n",
      "Epoch 88/150\n",
      "88/88 - 0s - loss: 6.9116 - dense_8_loss: 4.8632 - dense_9_loss: 2.0484\n",
      "Epoch 89/150\n",
      "88/88 - 0s - loss: 6.9328 - dense_8_loss: 4.8863 - dense_9_loss: 2.0465\n",
      "Epoch 90/150\n",
      "88/88 - 0s - loss: 7.0181 - dense_8_loss: 4.9730 - dense_9_loss: 2.0452\n",
      "Epoch 91/150\n",
      "88/88 - 0s - loss: 6.8957 - dense_8_loss: 4.8527 - dense_9_loss: 2.0430\n",
      "Epoch 92/150\n",
      "88/88 - 0s - loss: 6.9122 - dense_8_loss: 4.8715 - dense_9_loss: 2.0407\n",
      "Epoch 93/150\n",
      "88/88 - 0s - loss: 6.9392 - dense_8_loss: 4.8985 - dense_9_loss: 2.0408\n",
      "Epoch 94/150\n",
      "88/88 - 0s - loss: 6.8886 - dense_8_loss: 4.8517 - dense_9_loss: 2.0369\n",
      "Epoch 95/150\n",
      "88/88 - 0s - loss: 6.9012 - dense_8_loss: 4.8653 - dense_9_loss: 2.0359\n",
      "Epoch 96/150\n",
      "88/88 - 0s - loss: 6.9271 - dense_8_loss: 4.8927 - dense_9_loss: 2.0344\n",
      "Epoch 97/150\n",
      "88/88 - 0s - loss: 6.9207 - dense_8_loss: 4.8873 - dense_9_loss: 2.0334\n",
      "Epoch 98/150\n",
      "88/88 - 0s - loss: 6.8919 - dense_8_loss: 4.8624 - dense_9_loss: 2.0295\n",
      "Epoch 99/150\n",
      "88/88 - 0s - loss: 6.8795 - dense_8_loss: 4.8510 - dense_9_loss: 2.0285\n",
      "Epoch 100/150\n",
      "88/88 - 0s - loss: 6.8822 - dense_8_loss: 4.8539 - dense_9_loss: 2.0283\n",
      "Epoch 101/150\n",
      "88/88 - 0s - loss: 6.8855 - dense_8_loss: 4.8592 - dense_9_loss: 2.0263\n",
      "Epoch 102/150\n",
      "88/88 - 0s - loss: 6.8869 - dense_8_loss: 4.8624 - dense_9_loss: 2.0245\n",
      "Epoch 103/150\n",
      "88/88 - 0s - loss: 6.8632 - dense_8_loss: 4.8404 - dense_9_loss: 2.0228\n",
      "Epoch 104/150\n",
      "88/88 - 0s - loss: 6.8688 - dense_8_loss: 4.8477 - dense_9_loss: 2.0211\n",
      "Epoch 105/150\n",
      "88/88 - 0s - loss: 6.8639 - dense_8_loss: 4.8446 - dense_9_loss: 2.0193\n",
      "Epoch 106/150\n",
      "88/88 - 0s - loss: 6.8606 - dense_8_loss: 4.8419 - dense_9_loss: 2.0187\n",
      "Epoch 107/150\n",
      "88/88 - 0s - loss: 6.8721 - dense_8_loss: 4.8536 - dense_9_loss: 2.0185\n",
      "Epoch 108/150\n",
      "88/88 - 0s - loss: 6.8430 - dense_8_loss: 4.8273 - dense_9_loss: 2.0156\n",
      "Epoch 109/150\n",
      "88/88 - 0s - loss: 6.8946 - dense_8_loss: 4.8813 - dense_9_loss: 2.0133\n",
      "Epoch 110/150\n",
      "88/88 - 0s - loss: 6.8359 - dense_8_loss: 4.8238 - dense_9_loss: 2.0121\n",
      "Epoch 111/150\n",
      "88/88 - 0s - loss: 6.8605 - dense_8_loss: 4.8479 - dense_9_loss: 2.0126\n",
      "Epoch 112/150\n",
      "88/88 - 0s - loss: 6.8300 - dense_8_loss: 4.8188 - dense_9_loss: 2.0112\n",
      "Epoch 113/150\n",
      "88/88 - 0s - loss: 6.9088 - dense_8_loss: 4.9006 - dense_9_loss: 2.0082\n",
      "Epoch 114/150\n",
      "88/88 - 0s - loss: 6.8278 - dense_8_loss: 4.8214 - dense_9_loss: 2.0064\n",
      "Epoch 115/150\n",
      "88/88 - 0s - loss: 6.8391 - dense_8_loss: 4.8333 - dense_9_loss: 2.0058\n",
      "Epoch 116/150\n",
      "88/88 - 0s - loss: 6.8230 - dense_8_loss: 4.8188 - dense_9_loss: 2.0042\n",
      "Epoch 117/150\n",
      "88/88 - 0s - loss: 6.8175 - dense_8_loss: 4.8140 - dense_9_loss: 2.0034\n",
      "Epoch 118/150\n",
      "88/88 - 0s - loss: 6.8679 - dense_8_loss: 4.8655 - dense_9_loss: 2.0024\n",
      "Epoch 119/150\n",
      "88/88 - 0s - loss: 6.8366 - dense_8_loss: 4.8353 - dense_9_loss: 2.0013\n",
      "Epoch 120/150\n",
      "88/88 - 0s - loss: 6.8220 - dense_8_loss: 4.8213 - dense_9_loss: 2.0007\n",
      "Epoch 121/150\n",
      "88/88 - 0s - loss: 6.8509 - dense_8_loss: 4.8510 - dense_9_loss: 1.9999\n",
      "Epoch 122/150\n",
      "88/88 - 0s - loss: 6.8131 - dense_8_loss: 4.8150 - dense_9_loss: 1.9981\n",
      "Epoch 123/150\n",
      "88/88 - 0s - loss: 6.8776 - dense_8_loss: 4.8784 - dense_9_loss: 1.9992\n",
      "Epoch 124/150\n",
      "88/88 - 0s - loss: 6.8307 - dense_8_loss: 4.8349 - dense_9_loss: 1.9958\n",
      "Epoch 125/150\n",
      "88/88 - 0s - loss: 6.8193 - dense_8_loss: 4.8241 - dense_9_loss: 1.9953\n",
      "Epoch 126/150\n",
      "88/88 - 0s - loss: 6.8176 - dense_8_loss: 4.8243 - dense_9_loss: 1.9933\n",
      "Epoch 127/150\n",
      "88/88 - 0s - loss: 6.8874 - dense_8_loss: 4.8923 - dense_9_loss: 1.9952\n",
      "Epoch 128/150\n",
      "88/88 - 0s - loss: 6.8610 - dense_8_loss: 4.8685 - dense_9_loss: 1.9925\n",
      "Epoch 129/150\n",
      "88/88 - 0s - loss: 6.8252 - dense_8_loss: 4.8334 - dense_9_loss: 1.9917\n",
      "Epoch 130/150\n",
      "88/88 - 0s - loss: 6.7934 - dense_8_loss: 4.8028 - dense_9_loss: 1.9906\n",
      "Epoch 131/150\n",
      "88/88 - 0s - loss: 6.8008 - dense_8_loss: 4.8121 - dense_9_loss: 1.9887\n",
      "Epoch 132/150\n",
      "88/88 - 0s - loss: 6.8239 - dense_8_loss: 4.8350 - dense_9_loss: 1.9889\n",
      "Epoch 133/150\n",
      "88/88 - 0s - loss: 6.7881 - dense_8_loss: 4.8001 - dense_9_loss: 1.9880\n",
      "Epoch 134/150\n",
      "88/88 - 0s - loss: 6.8200 - dense_8_loss: 4.8320 - dense_9_loss: 1.9881\n",
      "Epoch 135/150\n",
      "88/88 - 0s - loss: 6.8241 - dense_8_loss: 4.8375 - dense_9_loss: 1.9867\n",
      "Epoch 136/150\n",
      "88/88 - 0s - loss: 6.7877 - dense_8_loss: 4.8027 - dense_9_loss: 1.9850\n",
      "Epoch 137/150\n",
      "88/88 - 0s - loss: 6.7926 - dense_8_loss: 4.8078 - dense_9_loss: 1.9848\n",
      "Epoch 138/150\n",
      "88/88 - 0s - loss: 6.7900 - dense_8_loss: 4.8073 - dense_9_loss: 1.9827\n",
      "Epoch 139/150\n",
      "88/88 - 0s - loss: 6.7823 - dense_8_loss: 4.7985 - dense_9_loss: 1.9838\n",
      "Epoch 140/150\n",
      "88/88 - 0s - loss: 6.7853 - dense_8_loss: 4.8021 - dense_9_loss: 1.9832\n",
      "Epoch 141/150\n",
      "88/88 - 0s - loss: 6.7861 - dense_8_loss: 4.8058 - dense_9_loss: 1.9803\n",
      "Epoch 142/150\n",
      "88/88 - 0s - loss: 6.8195 - dense_8_loss: 4.8374 - dense_9_loss: 1.9821\n",
      "Epoch 143/150\n",
      "88/88 - 0s - loss: 6.7720 - dense_8_loss: 4.7931 - dense_9_loss: 1.9789\n",
      "Epoch 144/150\n",
      "88/88 - 0s - loss: 6.7871 - dense_8_loss: 4.8077 - dense_9_loss: 1.9794\n",
      "Epoch 145/150\n",
      "88/88 - 0s - loss: 6.7691 - dense_8_loss: 4.7904 - dense_9_loss: 1.9787\n",
      "Epoch 146/150\n",
      "88/88 - 0s - loss: 6.7976 - dense_8_loss: 4.8194 - dense_9_loss: 1.9782\n",
      "Epoch 147/150\n",
      "88/88 - 0s - loss: 6.7804 - dense_8_loss: 4.8018 - dense_9_loss: 1.9786\n",
      "Epoch 148/150\n",
      "88/88 - 0s - loss: 6.7918 - dense_8_loss: 4.8132 - dense_9_loss: 1.9786\n",
      "Epoch 149/150\n",
      "88/88 - 0s - loss: 6.7614 - dense_8_loss: 4.7852 - dense_9_loss: 1.9762\n",
      "Epoch 150/150\n",
      "88/88 - 0s - loss: 6.7832 - dense_8_loss: 4.8066 - dense_9_loss: 1.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a1bb922a00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, [y_train,y_train_class], epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "yhat1, yhat2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.574\n"
     ]
    }
   ],
   "source": [
    "# calculate error for regression model\n",
    "error = mean_absolute_error(y_test, yhat1)\n",
    "print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.267\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy for classification model\n",
    "yhat2 = np.argmax(yhat2, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test_class, yhat2)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
